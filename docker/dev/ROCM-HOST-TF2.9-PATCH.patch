diff --git a/build_rocm_python3 b/build_rocm_python3
index d0454cf2a2d..411bd90999f 100755
--- a/build_rocm_python3
+++ b/build_rocm_python3
@@ -30,5 +30,6 @@ rm -f $TF_PKG_LOC/tf_nightly_rocm*.whl
 
 yes "" | ROCM_PATH=$ROCM_INSTALL_DIR TF_NEED_ROCM=1 PYTHON_BIN_PATH=/usr/bin/python3 ./configure
 bazel build --config=opt --config=rocm //tensorflow/tools/pip_package:build_pip_package --verbose_failures &&
+bazel build --config=opt --config=rocm //tensorflow:libtensorflow_cc.so --verbose_failures &&
 bazel-bin/tensorflow/tools/pip_package/build_pip_package $TF_PKG_LOC --rocm --nightly_flag &&
 pip3 install --upgrade $TF_PKG_LOC/tf_nightly_rocm*.whl
diff --git a/tensorflow/stream_executor/rocm/rocm_gpu_executor.cc b/tensorflow/stream_executor/rocm/rocm_gpu_executor.cc
index 66d9e230177..c6aaea12111 100644
--- a/tensorflow/stream_executor/rocm/rocm_gpu_executor.cc
+++ b/tensorflow/stream_executor/rocm/rocm_gpu_executor.cc
@@ -323,28 +323,36 @@ port::Status GpuExecutor::Launch(Stream* stream, const ThreadDim& thread_dims,
         hipfunc, rocm_kernel->GetGpuCacheConfig()));
   }
 
-  // prepare kernargs
-  // KernelArgsArrayBase keeps the pointer of arguments
-  // deference them here
-  std::vector<void*> kernargs;
-  KernelArgIterator iter = args.arg_iterator();
-  while (iter.has_next()) {
-    KernelArg arg = iter.next();
-    VLOG(2) << "*(arg.address): "
-            << reinterpret_cast<void*>(
-                   *static_cast<const uint64_t*>(arg.address));
-    kernargs.push_back(
-        reinterpret_cast<void*>(*static_cast<const uint64_t*>(arg.address)));
-  }
-
-  size_t size = sizeof(void*) * kernargs.size();
-  void* config[] = {HIP_LAUNCH_PARAM_BUFFER_POINTER, kernargs.data(),
-                    HIP_LAUNCH_PARAM_BUFFER_SIZE, &size, HIP_LAUNCH_PARAM_END};
+  // // prepare kernargs
+  // // KernelArgsArrayBase keeps the pointer of arguments
+  // // deference them here
+  // std::vector<void*> kernargs;
+  // KernelArgIterator iter = args.arg_iterator();
+  // while (iter.has_next()) {
+  //   KernelArg arg = iter.next();
+  //   VLOG(2) << "*(arg.address): "
+  //           << reinterpret_cast<void*>(
+  //                  *static_cast<const uint64_t*>(arg.address));
+  //   kernargs.push_back(
+  //       reinterpret_cast<void*>(*static_cast<const uint64_t*>(arg.address)));
+  // }
+
+  // size_t size = sizeof(void*) * kernargs.size();
+  // void* config[] = {HIP_LAUNCH_PARAM_BUFFER_POINTER, kernargs.data(),
+  //                   HIP_LAUNCH_PARAM_BUFFER_SIZE, &size, HIP_LAUNCH_PARAM_END};
+  void** kernel_params = const_cast<void**>(args.argument_addresses().data());
+ 
+//    return GpuDriver::LaunchKernel(
+//        GetGpuContext(stream), hipfunc, block_dims.x, block_dims.y, block_dims.z,
+//        thread_dims.x, thread_dims.y, thread_dims.z,
+// -      args.number_of_shared_bytes(), hipstream, nullptr, (void**)&config);
+// +      args.number_of_shared_bytes(), hipstream, kernel_params, nullptr);
+
 
   return GpuDriver::LaunchKernel(
       GetGpuContext(stream), kernel.name(), hipfunc, block_dims.x, block_dims.y,
       block_dims.z, thread_dims.x, thread_dims.y, thread_dims.z,
-      args.number_of_shared_bytes(), hipstream, nullptr, (void**)&config);
+      args.number_of_shared_bytes(), hipstream, kernel_params, nullptr);
 }
 
 int GpuExecutor::CalculateOccupancy(const DeviceDescription& device_description,
