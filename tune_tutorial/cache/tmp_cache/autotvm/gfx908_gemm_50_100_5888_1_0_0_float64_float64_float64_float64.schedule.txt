@main = primfn(data_A_1: handle, data_B_1: handle, T_matmul_TN_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {T_matmul_TN: Buffer(T_matmul_TN_2: Pointer(float64), float64, [50, 100], []),
             data_A: Buffer(data_A_2: Pointer(float64), float64, [5888, 50], []),
             data_B: Buffer(data_B_2: Pointer(float64), float64, [5888, 100], [])}
  buffer_map = {data_A_1: data_A, data_B_1: data_B, T_matmul_TN_1: T_matmul_TN} {
  allocate(T_matmul_TN.rf: Pointer(global float64), float64, [115000]), storage_scope = global {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 23;
    allocate(data_A.shared: Pointer(shared float64), float64, [1280]), storage_scope = shared;
    allocate(T_matmul_TN.rf.local: Pointer(local float64), float64, [1]), storage_scope = local;
    attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 10;
    attr [IterVar(blockIdx.z: int32, (nullptr), "ThreadIndex", "blockIdx.z")] "thread_extent" = 2 {
      for (ax0.outer: int32, 0, 6) {
        attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 50;
        for (ax1: int32, 0, 5) {
          if @tir.likely((((ax0.outer*50) + threadIdx.x) < 256), dtype=bool) {
            if @tir.likely(((((blockIdx.x*256) + (ax0.outer*50)) + threadIdx.x) < 5888), dtype=bool) {
              data_A.shared[(((ax0.outer*250) + (threadIdx.x*5)) + ax1)] = (float64*)data_A_2[(((((blockIdx.x*12800) + (ax0.outer*2500)) + (threadIdx.x*50)) + (blockIdx.y*5)) + ax1)]
            }
          }
        }
      }
      attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 5;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 50 {
        T_matmul_TN.rf.local[0] = 0f64
        for (k.inner: int32, 0, 256) {
          T_matmul_TN.rf.local[0] = ((float64*)T_matmul_TN.rf.local[0] + ((float64*)data_A.shared[((k.inner*5) + threadIdx.y)]*(float64*)data_B_2[((((blockIdx.x*25600) + (k.inner*100)) + (blockIdx.z*50)) + threadIdx.x_1)]))
        }
        T_matmul_TN.rf[(((((blockIdx.x*5000) + (blockIdx.y*500)) + (threadIdx.y*100)) + (blockIdx.z*50)) + threadIdx.x_1)] = (float64*)T_matmul_TN.rf.local[0]
      }
    }
    attr [IterVar(blockIdx.y_1: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 50;
    allocate(T_matmul_TN.repl.rf: Pointer(local float64), float64, [1]), storage_scope = local;
    allocate(reduce_temp0: Pointer(local float64), float64, [1]), storage_scope = local;
    attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 4;
    attr [IterVar(threadIdx.y_1: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 25;
    attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 6 {
      T_matmul_TN.repl.rf[0] = 0f64
      for (k.outer.v.inner: int32, 0, 4) {
        if @tir.likely((((threadIdx.x_2*4) + k.outer.v.inner) < 23), dtype=bool) {
          T_matmul_TN.repl.rf[0] = ((float64*)T_matmul_TN.repl.rf[0] + (float64*)T_matmul_TN.rf[(((((threadIdx.x_2*20000) + (k.outer.v.inner*5000)) + (blockIdx.y_1*100)) + (blockIdx.x_1*25)) + threadIdx.y_1)])
        }
      }
      attr [meta[tir.CommReducer][0]] "reduce_scope" = @tir.reinterpret(0u64, dtype=handle);
      @tir.tvm_thread_allreduce(1u32, (float64*)T_matmul_TN.repl.rf[0], True, reduce_temp0, threadIdx.x_2, dtype=handle)
      T_matmul_TN_2[(((blockIdx.y_1*100) + (blockIdx.x_1*25)) + threadIdx.y_1)] = (float64*)reduce_temp0[0]
    }
  }
}


